<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.4.1">Jekyll</generator><link href="https://pa-legg.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://pa-legg.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-09-10T10:50:24+00:00</updated><id>https://pa-legg.github.io/feed.xml</id><title type="html">Prof. Phil Legg</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">Wazuh, Ubuntu, Kali, Caldera — a super quick way of building a disposable cyber lab</title><link href="https://pa-legg.github.io/blog/2025/wazuh-ubuntu-kali-calderaa-super-quick-way-of-building-a-disposable-cyber-lab/" rel="alternate" type="text/html" title="Wazuh, Ubuntu, Kali, Caldera — a super quick way of building a disposable cyber lab"/><published>2025-08-01T16:16:16+00:00</published><updated>2025-08-01T16:16:16+00:00</updated><id>https://pa-legg.github.io/blog/2025/wazuh-ubuntu-kali-calderaa-super-quick-way-of-building-a-disposable-cyber-lab</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/wazuh-ubuntu-kali-calderaa-super-quick-way-of-building-a-disposable-cyber-lab/"><![CDATA[<h3>Wazuh, Ubuntu, Kali, Caldera — a super quick way of building a disposable cyber lab</h3> <p>Following on my series of Kasm-related posts, here I extend this further to build a cyber lab for logging machine activity using Wazuh SIEM, and for conducting attacks with Caldera. With Docker, Kasm, and a few tweaks, we can spin up a disposable lab in a matter of minutes.</p> <p>There are various tutorials online for trying to do similar setups to this — however, there are often snags and other issues that you find. Instead, this tutorial has been tested as of August 2025, and works with the Kasm Ubuntu VNC environments that I have been discussing in previous posts.</p> <h3>Step 1: Wazuh Manager in a Docker environment</h3> <p>First we set up Wazuh Manager in a Docker container. We <a href="https://documentation.wazuh.com/current/deployment-options/docker/wazuh-container.html">follow the guidance in their tutorial</a>.</p> <pre>git clone https://github.com/wazuh/wazuh-docker.git -b v4.12.0<br />cd ./wazuh-docker/single-node/<br />docker-compose -f generate-indexer-certs.yml run --rm generator<br /></pre> <p><em>Note: For those using ARM (e.g., Mac M processor) you will need to edit the docker-compose.yml file directly and add </em><em>platform: linux/amd64 for each of the three services. An example for the manager is shown below:</em></p> <pre>services:<br />  wazuh.manager:<br />    image: wazuh/wazuh-manager:4.12.0<br />    hostname: wazuh.manager<br />    platform: linux/amd64</pre> <p>Once the docker compose file is ready, we can bring up the containers:</p> <pre>docker-compose up -d</pre> <p>You should now be able to log in to the web based Wazuh dashboard at <a href="https://localhost:443">https://localhost</a> with the credentials admin and SecretPassword.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*BNbYhpgkzsBOLx-kQHcCxA.png"/></figure> <h3>Step 2: Set up our Docker network</h3> <p>We want to create a new Docker network that we will attach all our containers to.</p> <pre># Create a new network 172.20 that will connect all machines<br />docker network create --subnet 172.20.0.0/16 mycyberlab<br /><br /># Connect the 3 Wazuh nodes<br />docker network connect mycyberlab single-node-wazuh.manager-1<br />docker network connect mycyberlab single-node-wazuh.indexer-1<br />docker network connect mycyberlab single-node-wazuh.dashboard-1<br /><br /># Find the IP address of our manager node on our new network<br />docker container inspect single-node-wazuh.manager-1 | grep IPAddress</pre> <p>I can see two IP addresses (since we have a network that is set up with our Wazuh nodes, and a new network that we will use for connecting any monitored hosts).</p> <ul><li>“IPAddress”: “172.20.0.2”,</li><li>“IPAddress”: “172.18.0.3”,</li></ul> <p>We now know that the 172.20.0.2 address is how we can reach the manager system.</p> <h3>Step 3: Set up our Ubuntu endpoint</h3> <p>We fire up a new Ubuntu instance using the Kasm Docker images.</p> <pre>docker run --rm -it --user root --platform linux/amd64 --name myubuntu --shm-size=512m -p 6901:6901 -e VNC_PW=password kasmweb/ubuntu-jammy-desktop-vpn:1.17.0<br />docker network connect mycyberlab myubuntu<br /><br /># First update and install simple ping<br />apt update<br />apt install iputils-ping</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*05WI4tQZfqGsVSJw8td-LQ.png"/></figure> <p>We can see that we now have two network connections, and we should be able to ping our Wazuh manager successfully.</p> <p>Within this instance we set it up for logging:</p> <pre># Add the Wazuh repository and update<br />curl -s https://packages.wazuh.com/key/GPG-KEY-WAZUH | gpg --no-default-keyring --keyring gnupg-ring:/usr/share/keyrings/wazuh.gpg --import &amp;&amp; chmod 644 /usr/share/keyrings/wazuh.gpg<br />echo &quot;deb [signed-by=/usr/share/keyrings/wazuh.gpg] https://packages.wazuh.com/4.x/apt/ stable main&quot; | tee -a /etc/apt/sources.list.d/wazuh.list<br />apt update<br /><br /># We now pull the Wazuh agent, configure, install and start<br />WAZUH_MANAGER=&#39;172.20.0.2&#39;<br />WAZUH_AGENT_NAME=&#39;myubuntu&#39;<br />apt-get install wazuh-agent<br />/var/ossec/bin/wazuh-control start</pre> <p><em>Note: If you get Invalid server address found: MANAGER_IP, then in /var/ossec/etc/ossec.conf, replace MANAGER_IP with the expected IP address (i.e., 172.20.0.2).</em></p> <p>This deploys the agent and starts communicating with our server. All being good, we should see the agent appear in the Wazuh dashboard — we can restart the manager node if needed with:</p> <pre>docker container restart single-node-wazuh.manager-1</pre> <p><em>Note: We can see some logs however we need to explore how to get more useful and frequent logs from our system using tools like auditd, or how like sysmon would for Windows. Yes — there is also sysmonforlinux that we may add in here. Still playing around to decide our approach for the purpose of this exercise.</em></p> <p>With our SIEM running, and our Ubuntu endpoint logging to our SIEM, we can now move on to our adversary so that we can see something interest to log!</p> <h3>Step 4: Deploy a Kali instance and set up Caldera</h3> <p>As before, we can quickly spin up a Kali instance. We can also connect this to our network.</p> <pre>docker run --rm -it --user root --platform linux/amd64 --name mykali --shm-size=512m -p 6905:6901 -e VNC_PW=password kasmweb/kali-rolling-desktop:1.17.0<br />docker network connect mycyberlab mykali</pre> <p>Within the Kali instance, we can then do the following to <a href="https://github.com/mitre/caldera">install Caldera</a>:</p> <pre># Apply the keyring fix that was recently published<br />sudo wget https://archive.kali.org/archive-keyring.gpg -O /usr/share/keyrings/kali-archive-keyring.gpg<br /><br /># First update and some useful libraries<br />apt update<br />apt install iputils-ping<br />apt install python3-lxml<br />apt install npm<br /><br /># Create a Python environment for running caldera<br />apt install python3.13-venv<br />python3 -m venv caldera-env<br />source ./caldera-env/bin/activate<br /><br /># Pull caldera and install<br />git clone https://github.com/mitre/caldera.git --recursive<br />cd caldera<br />pip3 install -r requirements.txt<br />python3 server.py --insecure --build<br /></pre> <p><em>Note: If your requirements install throws an error, you may want to comment out lxml in requirements.txt and install manually as added above.</em></p> <p>Navigate to <a href="http://localhost:8888">http://localhost:8888</a> within the Kali instance, and use the username/password credentials red and admin to log in.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*l4GPnUmL8smy3_nWKKds_Q.png"/></figure> <h3>Recap</h3> <p>We now have have 3 components:</p> <ul><li>Wazuh SIEM running in a Docker container</li><li>Ubuntu desktop environment, running in a Docker container, that will serve as our target, with system logs being passed to our SIEM.</li><li>Kali desktop environment, running in a Docker container, that will serve as our attack, set up with the MITRE Caldera adversary emulation platform.</li></ul> <p>All this, from essentially 5 minutes of command line scripts! Wow.</p> <p>—</p> <p>Some other articles relating to Wazuh, Caldera, and AI integrations that may also be of interest!</p> <ul><li><a href="https://wazuh.com/blog/adversary-emulation-with-caldera-and-wazuh/">Adversary emulation with CALDERA and Wazuh | Wazuh</a></li><li><a href="https://socfortress.medium.com/introducing-wazuh-mcp-server-bridging-siem-and-ai-for-smarter-security-operations-ea9b5441dbba">🚀 Introducing Wazuh MCP Server: Bridging SIEM and AI for Smarter Security Operations</a></li><li><a href="https://socfortress.medium.com/ai-agent-for-your-open-source-siem-stack-is-here-wazuh-velociraptor-and-copilot-just-got-2e0542aac697">🚀 AI Agent for Your Open-Source SIEM Stack Is Here — Wazuh, Velociraptor, and CoPilot Just Got…</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=1ad693665fa5" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">More Fun with Kasm and Docker: Quickly spin up x86-based Ubuntu or Kali on macOS</title><link href="https://pa-legg.github.io/blog/2025/more-fun-with-kasm-and-docker-quickly-spin-up-x86-based-ubuntu-or-kali-on-macos/" rel="alternate" type="text/html" title="More Fun with Kasm and Docker: Quickly spin up x86-based Ubuntu or Kali on macOS"/><published>2025-07-30T20:41:21+00:00</published><updated>2025-07-30T20:41:21+00:00</updated><id>https://pa-legg.github.io/blog/2025/more-fun-with-kasm-and-docker-quickly-spin-up-x86-based-ubuntu-or-kali-on-macos</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/more-fun-with-kasm-and-docker-quickly-spin-up-x86-based-ubuntu-or-kali-on-macos/"><![CDATA[<p>Previously, I gave a quick example of running a Ubuntu/Kali virtual machine, accessible easily in a web browser using Kasm. If you missed it, <a href="https://medium.com/@plegg/quick-setup-of-a-virtual-machine-in-a-web-browser-using-kasm-and-docker-01f3445146d1">check it out here</a>.</p> <p>One of the biggest frustrations in recent years when it comes to virtual machines was the move from x86/AMD to ARM for Apple devices. However, a neat trick in Docker is that we can have it emulate a platform. Couple this with the Kasm VNC running Kali/Ubuntu, and we can actually spin up a quick web-based VM, and we can also choose whether we want it to be ARM-based or x86/AMD-based. This becomes really useful where some containers/apps will only run on x86 variants.</p> <p>Here are the one-liners that we need to fire up our Kasm instances quickly, supporting root and architectures as needed. We can use the command lscpu to then confirm that the VMs are running on the expected architecture.</p> <p>Thanks to <a href="https://forums.docker.com/t/run-x86-intel-and-arm-based-images-on-apple-silicon-m1-macs/117123">this message board</a> where they discussed running x86 Docker containers on Mac!</p> <h3>Ubuntu (ARM)</h3> <pre>docker run --rm -it --user root --platform linux/arm64 --shm-size=512m -p 6901:6901 -e VNC_PW=password kasmweb/ubuntu-jammy-desktop-vpn:1.17.0</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*Gn0c86v7ylGJ23jgQHqaFQ.png"/></figure> <h3>Ubuntu (x86/AMD)</h3> <pre>docker run --rm -it --user root --platform linux/amd64 --shm-size=512m -p 6901:6901 -e VNC_PW=password kasmweb/ubuntu-jammy-desktop-vpn:1.17.0</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*45DBNXer3M3peyzkUV2kKg.png"/></figure> <h3>Kali (ARM)</h3> <pre>docker run --rm -it --user root --platform linux/arm64 --shm-size=512m -p 6905:6901 -e VNC_PW=password kasmweb/kali-rolling-desktop:1.17.0</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*PgZ_paDRxfRgHzprHPPHog.png"/></figure> <h3>Kali (x86/AMD)</h3> <pre>docker run --rm -it --user root --platform linux/amd64 --shm-size=512m -p 6905:6901 -e VNC_PW=password kasmweb/kali-rolling-desktop:1.17.0</pre> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*W-k9grBhYWY451Zlp3MwWA.png"/></figure> <h3>One more tweak…</h3> <p>The above examples create a Docker container and then remove this when the container is terminated (since we are passing --rm).</p> <p>Depending on how you want to use the VMs, we may want to remove this for a persistant VM environment. In which case, we may also want to give our container a name so that we can refer to it easily and restart it where we left off.</p> <pre>docker run --name mykali -it --user root --platform linux/amd64 --shm-size=512m -p 6905:6901 -e VNC_PW=password kasmweb/kali-rolling-desktop:1.17.0<br />docker run --name myubuntu -it --user root --platform linux/amd64 --shm-size=512m -p 6901:6901 -e VNC_PW=password kasmweb/ubuntu-jammy-desktop-vpn:1.17.0</pre> <p>We can use the VM as expected, and terminate the container when we are ready. When we want to then use the VM again we simply start the container again.</p> <pre>sudo docker start mykali<br />sudo docker start myubuntu</pre> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=b982e4536f6c" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Part 1: Quick setup of a Virtual Machine in a Web Browser using Kasm and Docker</title><link href="https://pa-legg.github.io/blog/2025/part-1-quick-setup-of-a-virtual-machine-in-a-web-browser-using-kasm-and-docker/" rel="alternate" type="text/html" title="Part 1: Quick setup of a Virtual Machine in a Web Browser using Kasm and Docker"/><published>2025-07-17T19:36:06+00:00</published><updated>2025-07-17T19:36:06+00:00</updated><id>https://pa-legg.github.io/blog/2025/part-1-quick-setup-of-a-virtual-machine-in-a-web-browser-using-kasm-and-docker</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/part-1-quick-setup-of-a-virtual-machine-in-a-web-browser-using-kasm-and-docker/"><![CDATA[<p>Often I need to spin up Virtual Machines quickly for testing ideas, building class exercises, and other tinkering around. Virtual Machines are all well and good but get a bit time-consuming to set up and tear down. Docker is great for spinning environments up quickly, but may only give you the bare minimum or a CLI when you may want a bit more…</p> <p>So, I’ve been looking for a good way to have a remote desktop in a web browser for a virtual machine, that can be set up quickly.</p> <p>Enter Kasm. They have a set of Docker containers that support web remote desktop out of the box, and can quickly be deployed.</p> <p>Ubuntu Jammy Desktop— <a href="https://hub.docker.com/r/kasmweb/ubuntu-jammy-desktop-vpn">https://hub.docker.com/r/kasmweb/ubuntu-jammy-desktop-vpn</a></p> <p>Kali — <a href="https://hub.docker.com/r/kasmweb/kali-rolling-desktop">https://hub.docker.com/r/kasmweb/kali-rolling-desktop</a></p> <p>One snag — I wanted to be able to use apt install within my environment. Adapting the official documentation, I would add the “— user root” to the Docker command.</p> <p>docker run --rm -it --user root --shm-size=512m -p 6901:6901 -e VNC_PW=password kasmweb/ubuntu-jammy-desktop-vpn:1.17.0</p> <p>docker run --rm -it --user root --shm-size=512m -p 6905:6901 -e VNC_PW=password kasmweb/kali-rolling-desktop:1.17.0</p> <p>(In this example I’ve put Kali on 6905 so that I can run both instances together).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*ibaUyz57iDV0VxtO-ziYyQ.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*NQc12di2ZIJkbvtBehBX5Q.png"/></figure> <p>From one line, I can now connect to <a href="https://localhost:6901">https://localhost:6901</a>, use kasm_user / password as the VNC credentials, and I have a Ubuntu desktop instance accessible that I can update and add new packages to quickly and easily!</p> <p>As I’m running two instances (Ubuntu and Kali) I can share between them as they are on the same local subnet (however ping is not available by default).</p> <p>apt update</p> <p>apt install iputils-ping</p> <p>I now have two different OSs running in two browser windows able to communicate — and it took about 20 seconds to set up!</p> <p><a href="https://kasmweb.com">Nice one Kasm</a>.</p> <p>P.S. <a href="https://hub.docker.com/u/kasmweb?page=1&amp;search=">Kasm Tech DockerHub</a> page shows a bunch of different OSs and applications that can all be deployed in the same web-based manner — they even have a <a href="https://hub.docker.com/r/kasmweb/doom">Doom</a> image :)</p> <p>P.P.S. Kali may still require the update to the missing signing key that was widely documented recently — <a href="https://www.kali.org/blog/new-kali-archive-signing-key/">https://www.kali.org/blog/new-kali-archive-signing-key/</a></p> <p>Next</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=01f3445146d1" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">AI for rapid prototyping in education</title><link href="https://pa-legg.github.io/blog/2025/ai-for-rapid-prototyping-in-education/" rel="alternate" type="text/html" title="AI for rapid prototyping in education"/><published>2025-06-27T14:51:47+00:00</published><updated>2025-06-27T14:51:47+00:00</updated><id>https://pa-legg.github.io/blog/2025/ai-for-rapid-prototyping-in-education</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/ai-for-rapid-prototyping-in-education/"><![CDATA[<p>It seems that there are many educators and academics grappling with the idea of what modern AI tools mean for education, when a student may use AI to solve the problem or complete the assignment, and then everyone complains that the student has ‘cheated’…</p> <p>We need to move away from this way of thinking…</p> <p>AI techniques, such as those that have become synonymous like ChatGPT and Gemini, have the ability to help educators just like they are being used in many other disciplines. I use GPTs for coding and rapid prototyping of concepts and ideas that I want to test. At this point, it may then sound like it is merely for these ‘coders’ to dabble with, but with a few straightforward ideas any educators can harness this potential.</p> <blockquote>Here’s a simple prompt: <em>“Generate the code for a simple interactive webpage for demonstrating the concept of encryption for students.”</em></blockquote> <p>Sure enough, our trusted partner says “OK”, and then produces a simple HTML-based web application for teaching some basic encryption principles.</p> <p><em>&lt;!DOCTYPE html&gt;<br/>&lt;html lang=”en”&gt;<br/>&lt;head&gt;<br/> &lt;meta charset=”UTF-8&quot; /&gt;<br/> &lt;meta name=”viewport” content=”width=device-width, initial-scale=1.0&quot;/&gt;<br/> &lt;title&gt;Encryption Demo&lt;/title&gt;<br/> &lt;style&gt;<br/> body {<br/> font-family: Arial, sans-serif;<br/> max-width: 600px;<br/> margin: 2em auto;<br/> padding: 1em; …</em></p> <p>We can then take this code and save it as a .html file, or we could even embed this code directly within our VLE (Virtual Learning Environment). The screenshot and link below shows what this output gives:</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*SLjxg9oIz1uKSInCU8x6qA.png"/><figcaption>Interactive encryption demo generated in HTML using ChatGPT</figcaption></figure> <p><a href="https://pa-legg.github.io/resources/ai-web-examples/encryption-examples/encryption-example01.html">Example01</a></p> <p>This is a great little example to start with — we can perform caesar cipher with a given rotation parameter, and we can see the output of this in an interactive manner. Not only does GPT provide this, but it will also suggest ways that the code can be enhanced further — e.g., different decryption algorithms, and real-time encryption/decryption. We can simply say “Yes” to these additional ideas, and GPT will then run along making further iterations of our simple concept. The examples below show the further iterations.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*O5rk1Jpz-_pJ3W7CVUbMww.png"/><figcaption>Expanding our example further to include decryption stages</figcaption></figure> <p><a href="https://pa-legg.github.io/resources/ai-web-examples/encryption-examples/encryption-example02.html">Encryption Example 02</a></p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/1*AgpAIGgWmUUXuP5cRw1JhA.png"/><figcaption>Expanding futher still with multiple encryption schemes available</figcaption></figure> <p><a href="https://pa-legg.github.io/resources/ai-web-examples/encryption-examples/encryption-example03.html">Encryption Example 03</a></p> <p>I’ve used this for a few different subject areas, with different interactive components all generated automatically. I’ll be doing a few short follow ups to showcase these also.</p> <p>The key factor however, is that I can now use AI to create new, bespoke learning environments for my students. If I can do this and save time in the production, I can have students use the examples, and then use the class to elaborate further on the topic area, potentially with further interactive examples. You could even generate further interactive examples in partnership with your students! Talk about co-creation!! :)</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=32fe4a89bea8" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 09 — Future Research Directions</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics09future-research-directions/" rel="alternate" type="text/html" title="Security Data Analytics — 09 — Future Research Directions"/><published>2025-06-22T10:58:42+00:00</published><updated>2025-06-22T10:58:42+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics09future-research-directions</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics09future-research-directions/"><![CDATA[<h3>Security Data Analytics — Session 09 — Future Research Directions</h3> <p><strong><em>*** This material is session 9 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <p>We have covered a lot of ground through this course, from the initial ideas around cyber security analytics, through to managing workflows, machine learning and visualisation, and different applications of analysis that may be required. Of course, future research will continue to evolve and we will see greater uses of data analytics to understand the world around us and how best to secure this.</p> <h3>Visualisation for Cyber Security</h3> <p>The IEEE VizSec conference started in 2004 as the Workshop on Visualization and Data Mining for Computer Security, as a co-located event as part of the IEEE Vis conference — one of the largest International conferences on the topic of data visualisation. The conference is still an integral part of IEEE Vis, and continues to attract high-quality research publications. You can find more details about VizSec at <a href="https://vizsec.org/">https://vizsec.org/</a>. There is also an online proceedings browser available at <a href="https://vizsec.dbvis.de/">https://vizsec.dbvis.de/</a>.</p> <h3>Future of Data Analytics in Cyber Security</h3> <p>Here are just a small sample of articles and further reading that relate to the use of Machine Learning and Data Analytics for Cyber Security, ranging from Connected Autonomous Vechicles, HealthTech, and Industrial IoT — 3 key areas that are seeing significant impact from ML and data analytics, and that will plan an important role within society in our future.</p> <ul><li><a href="https://billatnapier.medium.com/introduction-to-machine-learning-and-splunk-1ef256add6b1">Introduction to Machine Learning and Splunk (Prof Bill Buchanan)</a></li><li><a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/661135/cyber-security-connected-automated-vehicles-key-principles.pdf">The Key Principles of Cyber Security for Connected Autonomous Vehicles</a></li><li><a href="https://arxiv.org/abs/2007.08041">A Survey on Security Attacks and Defense Techniques for Connected and Autonomous Vehicles</a></li><li><a href="https://www.bbc.co.uk/news/technology-55411830">Health to be on cyber-security’s front line in 2021</a></li><li><a href="https://www.sciencedirect.com/science/article/pii/S0378512218301658?casa_token=OvW__y7jq_4AAAAA:haGdYeEEo664ZN4XmMcSwBJY2RWjac3Ge22n0oP5PrxETA-1_b33_0B8eNQRARlA1KnmSKrSlsY">Cybersecurity in healthcare: A narrative review of trends, threats and ways forward</a></li><li><a href="https://www.nccoe.nist.gov/projects/use-cases/energy-sector/iiot">Securing the Industrial Internet of Things</a></li><li><a href="https://iiot-world.com/ics-security/cybersecurity/four-most-hard-to-solve-iiot-security-issues/">Four most hard to solve IIoT security issues</a></li></ul> <h3>Yet more resources</h3> <ul><li><a href="https://infosecjupyterthon.com/introduction.html">Infosec Jupyterthon</a>: A 2 day online workshop for all things Jupyter and how this can be used for InfoSec. With many contributors including speakers from Microsoft, this is a fantastic resource.</li><li><a href="https://mybinder.org/">MyBinder</a>: Turns a github repo into an interactive notebook environment for code reproducability.</li><li><a href="https://www.github.com/">GitHub</a>: Online code hosting repositories — over 11 million Jupyter notebooks hosted on GitHub currently.</li><li><a href="https://github.com/OTRF">Open Threat Research Forge</a></li><li><a href="https://github.com/OTRF/bloodhound-notebooks">Bloodhound Notebooks</a>: Notebooks created to attack and secure Active Directory environments.</li><li><a href="https://github.com/OTRF/Security-Datasets">Security Datasets</a>: The Security Datasets project is an open-source initiatve that contributes malicious and benign datasets, from different platforms, to the infosec community to expedite data analysis and threat research.</li><li><a href="https://github.com/OTRF/ThreatHunter-Playbook">ThreatHunter-Playbook</a></li><li><a href="https://www.unb.ca/cic/datasets/">Canadian Institute for Cybersecurity — Datasets</a>: An excellent data repository with related academic papers</li></ul> <h3>Further Reading</h3> <ul><li><a href="https://academic.oup.com/cybersecurity/article/1/1/93/2366512">Peter Hall, Claude Heath, Lizzie Coles-Kemp, Critical visualization: a case for rethinking how we visualize risk and security, Journal of Cybersecurity, Volume 1, Issue 1, September 2015, Pages 93–108, https://doi.org/10.1093/cybsec/tyv004</a></li><li><a href="https://informationsecurity.uibk.ac.at/pdfs/WB2020_sok_cyberrisk_snp.pdf">Daniel W. Woods and Rainer Bohme. Systematization of Knowledge: Quantifying Cyber Risk</a></li><li><a href="https://link.springer.com/article/10.1007/s12243-021-00889-1">Aouedi, O., Piamrat, K., Hamma, S. et al. Network traffic analysis using machine learning: an unsupervised approach to understand and slice your network. Ann. Telecommun. (2021). https://doi.org/10.1007/s12243-021-00889-1</a></li><li><a href="https://ieeexplore.ieee.org/document/9086268">M. A. Ayub, W. A. Johnson, D. A. Talbert and A. Siraj, “Model Evasion Attack on Intrusion Detection Systems using Adversarial Machine Learning,” 2020 54th Annual Conference on Information Sciences and Systems (CISS), 2020, pp. 1–6, doi: 10.1109/CISS48834.2020.1570617116.</a></li><li><a href="https://www.unb.ca/cic/datasets/ids-2017.html">Canadian Research Institute for Cybersecurity Datasets</a></li><li><a href="https://www.sciencedirect.com/science/article/pii/S016740481930118X">Markus Ring, Sarah Wunderlich, Deniz Scheuring, Dieter Landes, Andreas Hotho. A survey of network-based intrusion detection data sets</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=4b6811d7c2c0" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 08 — File, Image and Video Analytics</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics08file-image-and-video-analytics/" rel="alternate" type="text/html" title="Security Data Analytics — 08 — File, Image and Video Analytics"/><published>2025-06-22T10:58:18+00:00</published><updated>2025-06-22T10:58:18+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics08file-image-and-video-analytics</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics08file-image-and-video-analytics/"><![CDATA[<h3>Security Data Analytics — Session 08 — File, Image and Video Analytics</h3> <p><strong><em>*** This material is session 8 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <h3>Visualising Files</h3> <p>Often, we may want to understand the data that resides on a computer, such as what files exist and their content. Furthermore, there exist a wider range of file formats that we may want to examine — ranging from binary data and executable files, through to text files and office documents, and even multimedia content such as image and video formats. In this session, we will begin to examine methods of analysis and visualisation that can help to understand such content beyond typical manual investigation.</p> <h3>Binary File Visualisation</h3> <p>All data files stored on a computer system, no matter what their content is, can be expressed as a byte stream. This is the raw data that is processed by the computer to convert this data into a meaningful representation for the end-user, or to inform some other process or executable. As defined on Wikipedia, “the byte is a unit of digital information that most commonly consists of eight bits. Historically, the byte was the number of bits used to encode a single character of text in a computer and for this reason it is the smallest addressable unit of memory in many computer architectures.” An 8-bit representation can be used to express values in the range 0–255 (i.e., 00000000 to 11111111 in binary notation). Working with a byte stream for a file, we can then visualise these numerical values. Given the scale of information represented within a single file, we need a compact visual representation as we may be attempting to plot many values. Pixel visualisation is an effective technique where we can map numerical values to pixel colour values, to create an image based on the underlying numerical data.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/0*r9Ypfr-RdL5Sgnuc.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/0*qoipMwZ1nxApve4Z.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/512/0*cz7I95o6rorayshy.png"/></figure> <p>In this example, we simply map each byte of the file to a colour value running left-to-right, top-to-bottom (i.e., run-length). This preserves order in the file content. The visualisation size is determined by the size of the file, which may be useful, however can make comparative analysis difficult. In the above, we show 3 files (a docx, a docx with password protection, and a docx with AES encryption), and we use a fixed width of 512 bytes. We can begin to examine similarities and differences between these files using the visualisation scheme. Most notable is that the password example shows the additional password data, and some commonalities with the original file, whereas in the AES example the data is fully encrypted and not recoverable without the encryption key.</p> <p>Another approach is similar to that of ‘n-grams’ in text analytics, where we consider pairs of bytes to form a ‘digram visualisation’. In this setting, we take each pair of bytes and treat them as the X and Y coordinates to plot a point on a scatter plot. Points can be scaled based on number of occurrences if necessary, or colour-coded based on byte position or sequence. Below we can see examples of ‘jpeg’ file, a ‘txt’ file and a ‘docx’ file.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/492/0*o_A8cU_obXoun528.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/488/0*L485CiiXEhX9D7JK.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/502/0*Sl4dRF3ELOuVKZOT.png"/></figure> <p>In the examples, the scatter plot is bound between the values of 0–255, and so helps maintain a consistent representation to help comparative analysis (e.g., frequency of byte pairs, density of byte pairs). A tri-gram could be created using triplets of bytes and plotted using a 3-D scatterplot (see examples at <a href="https://codisec.com/binary-visualization-explained/">https://codisec.com/binary-visualization-explained/</a>).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/658/0*5zZFuq5dBPxzPVEx.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/655/0*ue7MVIvE2aOJb9mI.png"/></figure> <h3>Image and Video Analysis</h3> <p>Whilst binary file visualisation can be utilised for all forms of digital data, images and videos are a unique data format that lend themselves to further analysis. As visual stimuli, there are inherently understood and interpreted by humans. Image and video files are particularly large compared to many other file formats that are commonly used on most computer systems. Furthermore, image and video data has inherent spatial information that is fundmental for understanding their content. We will explore this further in this section.</p> <p>Firstly, why may we be interested in image and video analysis for security? Closed circuit television (CCTV) has been used for many years to monitor physical environments from a security perspective so that incidents can either be identified at the time of the event, or at the very least, be examined after the incident has occurred. This results in many hours of video footage, that is likely difficult to search and retrieve specific content from. Beyond searching video based on time, how may we be able to search video based on other characteristics, such as when a person wearing a blue jacket is identified? We may also want to identify more sophisticated concepts, such as when particular actions occur (activity recognition), when particular persons are in the scene (facial recognition), or when a change in behaviour is observed (anomaly detection). In many ways, what we are interested in is a way of summarising video content, where a video is denoted as a series of sequential images of which we need to filter the volume of data being examined.</p> <p>To motivate this example further, let us first recap on video attributes. A video is essentially a stack of sequential images. A single colour image is expressed by a computer as a 3-dimensional matrix: width x height x channels (where channels is typically RGB — red, green and blue). A video can therefore be expressed as a 4-dimensional matrix: width x height x channels x frames. For our example, we have a short video of 2 minutes 32 seconds. At the standard 30 frames a second, we have 4574 frames that make up the video. Our video has a frame height of 480 pixels and a frame width of 360. In short, our short video has over 2 billion data points.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/536/0*bbHAGUwVgdP4eqrq.png"/></figure> <p>What may we want to achieve from our analysis? Firstly, we may want to identify changes in our video stream, for example, if we have a CCTV stream, can we identify key frames where something may have changed? Secondly, can we group (cluster) similar frames together? This may help us to group similar patterns of activity, and identify activities that stand out as different in some way. For our examples, we will work with the McGill Real-World Face Video Dataset which is available online (and via Blackboard). It consists of 20 unique users where each users is filmed for a short interview clip of a couple of seconds. We will aim to identify changes in the scene (i.e., when a new users appears in the video) and also cluster frames for each user together.</p> <p>As our first stages of analysis, we need to make the data more manageable to work with. We can begin by extracting a single frame per second (rather than 30 frames per second). Since we are not trying to track motion between frames this is fine for our application, and more importantly, makes the problem much more manageable at 153 frames rather than 4574. Secondly, we can reduce each video frame to a greyscale image, meaning that we have only a single colour channel rather than RGB. Again, colour is not required for the purpose of our application so we can afford to remove this. We now have a set of 153 greyscale images that represent our video, where each image is 480x360 resolution (172,800 pixels). We are going to adopt a technique from earlier in the course of principal component analysis (PCA). Recall that PCA will take high dimensional data and reduce this to a low dimensionality (e.g., 2 or 3-dimensional). Each point in our projection should represent a single image, and so the high-dimensional data is essentially the set of pixels that make up an image. Whilst spatial information in images is important for us humans to understand image content, it matters little to a machine. Therefore, we could reshape our image matrix, so that instead of being rectangular, it is a single row of data, or to put it another way, it is a vector of size (1, 172800). Providing we remap each frame in the same manner, then each column in our new matrix represents a unique pixel position that can be compared across all frames of our video. Having remapped each image frame to be a vector, we then stack these in sequence to form a new matrix of size (153, 172800).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/496/0*nTDUAW6ssCwhEqR5.png"/></figure> <p>Having remapped our data, we can now simply perform PCA on our matrix — as discussed before this will essentially identify the features (columns) of greatest variance across all instances (i.e., image frames) of our data. Luckily, we can use the sci-kit learn library to perform this task quickly and easily. We can plot the resulting values as a scatter plot, where we can begin to identify points that have clustered together. We now have a set of unlabelled points, and so as we have seen earlier in the course, we can use k-means clustering to assign labels to each point. We know in advance that k should be 20 — we have 20 unique users in the video data — and so having performed k-means clustering we can colour-code the scatter plot according to the group assignment. That’s it — we have now taken a video and identified the similarity between extracted image frames to cluster similar frames together.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/679/0*F74q3iKshyn7higm.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/684/0*GkW8ILmBAQoovtXb.png"/></figure> <p>To check this, we could display all images within a given group to see whether the frames do in fact appear similar — here we can see that these 12 frames all show the same woman. It should be noted that this method may not give perfect results — for example, removal of RGB may loss too much information — but hopefully it demonstrates the concept.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/679/0*RPiaUCqIz8TXc4Wb.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/680/0*BohlUP4WiR4Lfn5e.png"/></figure> <p>As for recognising change between video frames, we can easily use the same matrix remapping to achieve this. For each row, we calculate the absolute difference in pixel values between this row and the next. We can then summarize the total pixel differences using the mean to express this as a single difference value between two frames. Using a line plot as shown here, we can observe peaks that are likely the scene changes in the video, and so we can identify an appropriate threshold for scene change detection either manually using the plot, or automatically by separating the peaks from the smaller frame differences (which are a result of both motion and image noise / video compression artefacts).</p> <h3>Summary</h3> <p>We have discussed methods for visualising file content, be it as raw binary data in the form of a byte stream, or in the case of richer multimedia such as image and video, how we can process raw image pixel data. One of the key points to raise is that we have been able to adopt many of the methods we have used previously in the course. This is important to recognise, since file data is essentially just another form of data that we can work with. Image and video present some further interesting challenges, primarily due to the inherent understanding that humans have of images and videos, however we can perform analysis on pixel data much as we can of any other data attributes.</p> <p>Multimedia content such as image and video is shared online in such volumes nowadays that we need better methods for analysis of such data. As discussed, videos and inherent to humans but mean little to a machine — so how would a machine work to prevent the sharing of indecent video content? Given the nature of re-posting and sharing of videos, this becomes important to stop the spread of malicious or dangerous content online. Examples have ranged from videos of terrorist attacks, unwanted sharing of sexual videos, and intentional graphic violence injected in children’s video. Given how online video is now considered general behaviour for many households, ensuring video content is safe for users is a vital area of protecting cyber space. Video analysis also naturally plays into insider threat detection, open source intelligence, and forensic investigations. As technology continues to evolve with connected autonomous vehicles, health tech, and industrial IoT, video streaming and video analysis is a crucial aspect of such systems to analyse, detect and respond to real-time conditions — be it reacting to a moving vehicle to avoid a collision, or adjusting a medical dosage based on image analysis of a patient. Cyber criminals wanting to compromise such systems will inevitably exploit image analysis techniques — a prime example being the generating of deep fakes to falsify video content that is shared remotely. Therefore, as cyber security professionals, it is important to understand and acknowledge these attack vectors, and begin to consider how best to defend against them. As adversarial learning proves, relying on artificial intelligence alone may not help to combat the situation, but understanding how to process image and video content, and how to contextual video content to understand the story being told will ensure that as defenders we are better prepared to protect our systems, especially those that are becoming more and more embedded within our society.</p> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=ca74bf915312" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 07 — Text Analytics</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics07text-analytics/" rel="alternate" type="text/html" title="Security Data Analytics — 07 — Text Analytics"/><published>2025-06-22T10:57:39+00:00</published><updated>2025-06-22T10:57:39+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics07text-analytics</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics07text-analytics/"><![CDATA[<h3>Security Data Analytics — Session 07 — Text Analytics</h3> <p><strong><em>*** This material is session 7 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <p>As a primary form of communication, the written (or spoken) word provides a massive wealth of information for many applications. For the most part we have been dealing with numerical data so far. Yet, there are plenty of applications where we would want to examine text rather than numerical data — for example, email analysis, social media analysis, product reviews, legalese, document classification, and many more. Natural Language Processing (NLP) is a subject area in it’s own right — but for now, we will introduce the topic and explore some of the methods that could be used to for security analysis.</p> <p>What kind of “processing” may we want to achieve? We may want natural language generation (e.g., creating a chat bot that can respond to user questions), topic modelling (e.g., classification of document types), sentiment analysis (e.g., understanding emotional traits), text clustering (e.g., relationship between words), named entity recognition (e.g., what are the ‘things’ mentioned in a sentence — such as the blue car drove down the road). We may also want to identify key words of interest from a large text corpus, we can use a method known as term frequency-inverse document frequency which we will discuss shortly.</p> <p>How does text analytics relate to security needs? We may want to examine user emotion through their use of language — common in psychological assessment such as insider threat detection. We may want to classify conversations or news articles — especially given the wealth of text information online, and how rapidly new content appears through social media sites and the like. We may also want to authenticate users based on their language, or observe when language may change — this could be in part of identifying if information is genuine, or if an attempt is made to falsify information from a given source. The rise of “fake news” on social media makes this an important security issue related to how we trust and scrutinise online materials. As alluded to earlier, humans are excellent at understanding language, however computers are not. Therefore, we need to establish models that operate in similar ways to how we understand and interpret language — recognising that these will be limited in their performance but that they are much more scalable than human resource — leaving humans to then verify the outcomes of the models.</p> <h3>Word Occurrences</h3> <p>A simple approach to begin with would be to examine the occurrence (or count) of each unique word within a document. This example takes the Computer Security wikipedia article, and assesses the number of times each word appears on the page to develop a topic model. As we may expect, “security” is the most used word in the article — however we can learn some other useful information from this, such as “cyber”, “information” “network”, and “systems” also occurring frequently. This essentially allows us to build a dictionary of related terms that could be used to connect topics together. This concept is often referred to as a ‘bag of words’ model.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/479/0*bpWghmINhb748pvh.png"/></figure> <p>We can use this same approach to assess how frequently a given word (or set of words) occur within some text (or a set of documents). Whilst this sounds fairly simple, it is very effective. It is essentially how password brute forcing works — take the rockyou dataset of 14 million passwords, and scan a set of webpages to see if these dictionary terms occur, and you could potentially identify websites that are based on weak credentials. This opens up a range of possibilities in the scope of open-source intelligence (OSINT) — how to gather and analyse information that is openly available online. Other uses may explore dictionaries such as the Linguistic Inquiry Word Count (LIWC) that is popular in psychology and can be used to identify positive and negative sentiment, along with other linguistic features.</p> <p>Another simple yet powerful extension to search for word occurrences, is searching for word pairs (or triples, etc.). We call these <strong>n-grams</strong>, where n is the number of words occurring together. Here, we now start to uncover much more context about the words, given that we can see what typically comes before or after the words of interest.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/471/0*SAIse4wNyDw3OBdV.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/481/0*pObwlmu8ndnrfKbZ.png"/></figure> <h3>Term Frequency — Inverse Document Frequency</h3> <p><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf">TF-IDF</a> is a powerful technique to identify word of interest based on their occurrence, whilst also not being hindered by commonly-occurring words that may not necessarily be of interest. Suppose we have a set of documents. For a single document, we may be interested in how often a particular word is mentioned. However, if this word is truly of importance to that specific document, then the expectation is that it should not be so frequent across other documents. For example, if we had documents reporting common vulnerabilities (e.g., CVEs), then a specific vulnerability such as Heartbleed may be highly mentioned in its respective document, but not mentioned in any others. This would mean that it should score higher than a word such as “cyber”, which whilst it may occur more frequently in the same document, may also occur quite frequently across all documents.</p> <p>TF-IDF is calculated as follows:</p> <ul><li>TF(t) = number of times t appears in a document / total number of terms in document</li><li>IDF(t) = log (total number of documents / number of documents with t in)</li></ul> <p>Let’s consider our example using the words “Heartbleed” and “Cyber”. Suppose “Heartbleed” occurs 10 times within a 100 word document: TF(Heartbleed) = 10/100 = 0.1. Suppose we have 1000 documents and “Heartbleed” occurs in 10 of these: IDF(Heartbleed) = log(1000 / 10) = 2. Then, TF-IDF = TF * IDF = 0.1 * 2 = 0.2. Suppose now we look at the word “Cyber”, and assume it occurs 30 times within the 100 word document: TF(Cyber) = 30/100 = 0.3, but it also occurs in 750 of the 1000 documents: IDF(Cyber) = log(1000 / 750) = 0.124. Then, TF-IDF = TF * IDF = 0.3 * 0.124 = 0.0372. Here, Heartbleed is scored higher than Cyber because in relation to the overall document set it is deemed of greater significance.</p> <h3>Recommender Systems</h3> <p>How can a system learn to make recommendations? Recommender systems become popular through their use in market basket analysis (e.g. Tesco Clubcard) for predicting shopping habits and recommending products that would likely result in a purchase, however they can be used in other applications to identify groupings of similarity and relations between items (e.g., words).</p> <p>Suppose we have 10 popular items, and we have a record of 10 users as to whether they would buy that item or not (denoted by either a 1 or a 0). We can use this information to identify items that are purchased together, or customers who are similar in their purchasing habits. If we have a new customer, we can initiate a “cold” profile simply by taking the average of all existing users. If we learn that this new user then likes chicken, we can update our recommendations by filtering, so that we average all users who also like chicken, to obtain a revised prediction for this user. In this example, if Kyle was a new customer there would be 90% probability of him buying pasta (since 9 out of 10 of existing customers do already) and 50% probability of him buying a pear (since 5 out of 10 existing customers do already). If we then observe that Kyle buys beef (i.e., he adds it to his basket), we can filter our dataset based on customers who also buy beef. This would then indicate a 100% probability of him also buying pasta (all customers who have bought beef have also bought pasta), and a 75% probability of buying a pear (since 3 of 4 customers who bought beef also bought a pear). Likewise, the probability of Kyle buying an apple goes from 40% to 0% because of him buying beef. There is a practical notebook available where you can explore this concept further.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/548/0*rkeVMr4kQzbz369s.png"/></figure> <p>Now instead of this example being about items in a shopping basket, what if this was about words in a news article? We could learn to characterise topics such as ‘sports’, ‘politics’, ‘entertainment’, and ‘travel’, and we could identify articles that appear similar to each other — essentially allowing us to cluster data much like we have done earlier in this course. In a similar manner, we could also recommend the next word in a passage of text — much like how predictive text services function. Text models therefore can be used to both predict what will appear next, and also as a means of validate what has appeared next, and whether this conforms to the expected model of behaviour.</p> <h3>Spam Detection</h3> <p>Another popular task for text analytics is identifying whether an email is spam or not. As the use of email has exploded, so has the volume of spam email received — however many providers have developed good models for detecting between genuine email and spam. How do they work? Many systems use an approach known as Naïve Bayes, based on Bayes’ Theorem: P(spam | X) = P(X | spam) * P(spam) / P(X).</p> <p>This equation denotes conditional probabilities, and can essentially be described as the following:</p> <ul><li>P(spam | X): What is the probability of this email being spam, given that it contains the word X?</li><li>P(X | spam): What is the probability of the word X occurring, given that this email is spam?</li><li>P(spam): What is the probability of this email being spam?</li><li>P(X): What is the probability of the word X occurring?</li></ul> <p>Even with incomplete data, we can begin to populate values for this equation based on observations we have seen in our data (i.e., in the email set we already have). Over time, our probabilities can be updated so that our spam detection improves as new data is observed (essentially by clicking the ‘junk’ option to inform the system of undetected cases). This is a powerful technique using Bayes’ — we can not possibly have a model for all types of spam email as there are infinite permutations of spam — however conditional probability allows us to estimate this efficiently. <a href="https://hackernoon.com/how-to-build-a-simple-spam-detecting-machine-learning-classifier-4471fe6b816e">An example of using Naïve Bayes for spam detection is available here</a>.</p> <h3>More on Text Analytics</h3> <p>As mentioned at the beginning of this section, there is a wealth of ongoing research and development in the area of text analytics that is increasingly useful for examining online materials and informing decisions about data (e.g., social media posts, fake news, etc.). <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a> (RNN) are a special neural net architecture that work particularly well on text as they are designed for sequential data. We can consider text to be sequential as there is a specific order to words to make up a structured and meaningful sentence (e.g., “The cat sat on the…” — a RNN would likely predict the next word to be “mat”). In particular, <a href="https://en.wikipedia.org/wiki/Long_short-term_memory">Long Short-Term Memory</a> (LSTM) networks are form of RNN that are widely used, which overcome some of the early limitations in RNNs for how historical information is maintained over time. The main distinction between these methods compared to traditional neural networks, is that RNN and LSTM take a sequence as an input (e.g., a set of features with some inherent order, such as a time-series), rather than a single observation of data (e.g., a set of features, or a single image)</p> <p>We have shown methods that rely on feature representation, such as “one-hot encoding” of words to numerical vectors — essentially converting a list of words to a vector of zero, where a one then represents the specific word. Whilst this can work in some cases, it can be constrained when a large word list is required (e.g., the complete English language). Other language models exist, for example, <a href="https://en.wikipedia.org/wiki/Word2vec">Word2Vec</a> has become adopted as a popular method for word embeddings. This essentially provides a model that can convert a given word to a vector representation in a more compact representation (e.g., an embedding) compared to “one-hot encoding”. This is similar in concept to PCA — it provides a dimensionality reduction on the data to present a meaningful yet compact representation. Word2Vec can be used to define a ‘continuous bag of words’, where given a set of words, what one word would fit within the set. Similarly, it can also be used to define ‘skip-grams’, where given a single word, what set of words would fit with this? We can see that these two methods are the inverse of each other. Extensions to the Word2Vec model have been proposed such as <a href="https://medium.com/wisio/a-gentle-introduction-to-doc2vec-db3e8c0cce5e">Doc2Vec</a>, which generates vectors to summary complete documents based on the Word2Vec model, offering a model compact representation for larger document analysis task.</p> <p>In recent years there has been a great interest in language models, and developing automated models for tasks such as chatbots and image captioning. If we consider a single word as a vector, a “simple” model could be considered as a vec2vec model (e.g., word translation). In our earlier example, we may have a sequence of words that then predict a single output word (e.g. predictive text), which we could consider as seq2vec. By extension, we then may also be interested in models that adopt vec2seq (a single input mapping to a sequential output) and <a href="https://en.wikipedia.org/wiki/Seq2seq">seq2seq</a> (a sequential input mapping to a sequential output). <a href="https://keras.io/examples/nlp/lstm_seq2seq/">Language translation</a> could be considered as seq2seq since we may have a variable length input and a variable length output. Another good example would be for a conversational agent (e.g., a chatbot), since the length of the input (i.e., number of words in the question) may vary in length each time, and likewise the length of the output (i.e., the answer given by the system) may also be a variable length. Text analytics and language models are perhaps the most groundbreaking area of research in delivering artificial intelligence. <a href="https://en.wikipedia.org/wiki/GPT-3">Generative Pre-trained Transformer 3</a> (GPT-3) was released in 2020 by OpenAI in their research paper <a href="https://arxiv.org/abs/2005.14165">“Language Models are Few-Shot Learners”</a>. It uses 175 billion parameters in their learning model, but achieves near-human accuracy. Whilst it can do traditional text tasks like sentence completion, they demonstrate it’s effectiveness for truly understanding text, such as executing commands as described by a human — from building applications based on a written description, smart assistants that can recognise tasks and provide recommendation, and many other examples that are available online. There are two videos in particular that describe just some of the possible applications by <a href="https://www.youtube.com/watch?v=_x9AwxfjxvE">2 minute papers</a> and by <a href="https://www.youtube.com/watch?v=8psgEDhT1MM">Half Ideas</a>. Since then, we have seen the likes of ChatGPT and GPT-4 take to the mainstream, with incredible growth in model size, contextual understanding, and practical application. With the Internet serving to inform a model, and compute power ever-increasing, there is a great wealth of future research opportunity to be explored.</p> <h3>Further reading</h3> <ul><li><a href="https://onlinelibrary.wiley.com/doi/full/10.1002/spy2.9">Ahmed H., Traore I. and Saad S. Detecting opinion spams and fake news using text classification, Security and Privacy, 2018; 1:e9. https://doi.org/10.1001/spy2.9</a></li><li><a href="https://research.google/pubs/pub46201/">Vaswani A., Shazeer N., Parmar N., Uszkoreit J., Jones L., Gomez A., Kaiser L. and Polosukhin I. Attention is All You Need, NIPS, 2017; https://research.google/pubs/pub46201/</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=72620bdd0028" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 06 — Visual Analytics</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics06visual-analytics/" rel="alternate" type="text/html" title="Security Data Analytics — 06 — Visual Analytics"/><published>2025-06-22T10:57:02+00:00</published><updated>2025-06-22T10:57:02+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics06visual-analytics</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics06visual-analytics/"><![CDATA[<h3>Security Data Analytics — Session 06 — Visual Analytics</h3> <p><strong><em>*** This material is session 6 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <h3>What do we mean by “Visual Analytics”?</h3> <ul><li>“Visual Analytics is the science of analytical reasoning supported by a highly interactive visual interface.” [Wong and Thomas 2004]</li><li>“Visual Analytics combines automated analysis techniques with interactive visualisations for an effective understanding, reasoning and decision making on the basis of very large and complex datasets” [Keim 2010]</li><li>“Detect the expected and discover the unexpected”</li></ul> <p>We have already discussed statistics, machine learning, and visualization. Visual analytics is essentially the combination of all three — the use of interactive visual interfaces to support statistical and analytical reasoning about data. A key emphasis here is the interactivity of the system — much like the knowledge generation feedback loop and the data science workflows discussed in Section 2, visual analytics is about how we develop analytical reasoning through iterative use of the system to interact, filter, and zoom in on key details of the data, as part of the exploration process. We have discussed static forms of data visualisation in Section 5, however the greatest challenge of any visualization is carefully deciding on what data should be shown, and how this should be represented. Visual analytics essentially allow us to interactively update the parameters of the visualization to create a dynamic and engaging interactive experience that helps inform decision making.</p> <p>If we consider automated methods, and we consider visualization methods, what are their strengths and weaknesses? Automated methods scale well to large data, however they may suffer from local optima problems, or run in a “black box” fashion that does not facilitate understanding of their process. Visualisation methods can be interactive, but can suffer from scalability. Visual analytics aim to combine the best of both approaches, where a user will alternate between visual and automated methods, and provides a collaborative approach for problem-solving and story-telling between the user and the machine.</p> <p>Let us consider the ability matrix here. We know that computers excel in some tasks, yet humans excel in others. Visual analytics aims to find the appropriate balance between the two. Often, people describe it as “providing insight” — yet, we need to consider “what do we mean by insight?”. Insight is something that is generated by a human, not a computer. So then how does a computer system (e.g., a visual analytics tools) help to generate insight? <a href="https://arxiv.org/pdf/1305.5670.pdf">Arguably, visualization and visual analytics are about “saving time” in a manner that supports cognition</a>.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/630/0*4Nwqzpk6hbONuHBh.png"/></figure> <h3>Dashboards</h3> <p>Dashboards are now widely used in many analysis platforms. The term originates from the car dashboard — we do not need to know every detail about the underlying system, such as the exact operations of cylinders and other mechanisms under the bonnet, however we do need the key details such as current speed, and we need a means to be alerted when things go wrong. The same is true in many cyber security scenarios — what we want to know is whether the infrastructure is operating as intended, some key details about the operation of the infrastructure, and if there is a problem, will the dashboard alert us correctly and in a timely-manner, with useful and meaningful information such that we can diagnose the problem and return to normal operations. A simple Google search for “visual analytics dashboard” will reveal a number of different designs and structures that have been used. Key summary statistics shown using pie charts and radial plots are often quite common — used in a number of “business” dashboards for presenting company financials. Key here is that these are for explanatory visualisation, they help convey the story or narrative. When interacting with a dashboard, it is about exploration, and so we can begin to understand how a dashboard can help achieve both focus-and-context, or overview and detail. Many dashboards may also “link” visualisations — whereby interactions and selections in one chart may update all related charts. Combining interaction across different linked visualisations makes dashboards a very powerful and effective form of exploration.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/460/0*MmHLTnXaWR_hROFg.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/425/0*vbFYXsOpA9B-bf6X.png"/></figure> <p>We introduced Plotly in our visualisation practical, and more recently, Plotly Dash has become <a href="https://plotly.com/dash/">“the most downloaded, trusted framework for building ML &amp; data science web apps.”</a> It is popular since it is written in Python, yet produces rich HTML-based interactive visualisations, without the need for further languages such as Javascript.</p> <h3>User Interaction</h3> <p>Humans learn by “doing” — it is the same in visualisation. It allows users to examine how something works, and specifically, it allows us to assess the strengths and weaknesses in our analysis. Typical interactions may include parameter selection (e.g., selecting a date range), filtering and selection (e.g., selecting a particular group of users), brushing (e.g. selecting a particular region on an axis), reordering (e.g., changing the data on an axis), and zoom (e.g., increase detail for a given region on a map). It is useful to think about interaction components such as those used in HTML 5 such as radio buttons, checkmark buttons, sliders, buttons, date time selections, as well as operations such as click, drag, hover, and focus. As this course primarily uses Python Notebooks, we can incorporate <a href="https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20Basics.html">“Widgets”</a> such as sliders, text entry, drop-down menus, radio buttons, buttons, date and colour pickers, file upload dialogs, tabs, and accordions, and <a href="https://ipywidgets.readthedocs.io/en/stable/examples/Widget%20List.html">many more</a> directly into our notebooks to interact with Pandas. We will explore how to achieve this further in our practical work.</p> <p>A number of interaction methods have evolved in recent times: mouse and keyboard, stylus pen, touchscreen, hand gestures (such as Leap Motion and Kinect), and voice. When designing systems, we need to be mindful of the intended mode of operation, and the associated costs of interactions. Amazon Alexa is a prime example of voice command — it allows hands-free operation of a system to perform tasks such as playing music and listening to weather reports. However, it may be less appropriate to inspect a parallel coordinates plot via voice — it may be difficult to articulate exactly what interaction is required, or it may be that the commands are simply too long for them to be convenient any more. Likewise, hand gestures work well for video games that may be about an immersive experience, but wouldn’t neceessarily lend themselves well for searching a database. We have to think about tiredness and fatigue caused by any interaction method, and the complexity of the interactions. Mouse and keyboards remain most common in many computing applications, due to their familiarity for users. Yet, users who have been primarily exposed to touchscreens and touch keyboard (especially on mobile devices) may find they can type quicker on a mobile than a traditional keyboard. Therefore, designing effective user interaction involves knowing the intended audience, and how they are expected to use the system, and for what duration. Some systems may seek to combine multi-modal interactions — such as voice and touch. The <a href="https://chi2021.acm.org/">ACM CHI conference</a> is a long-standing academic venue for research publications in the area of human-computer interaction.</p> <h3>Challenges in Visual Analytics</h3> <p>You may hear talk about “big data” — yet we need to ask what the actual investigation is that requires big data. Humans can not comprehend the complete dataset, and machine may not be able to “process” the complete dataset (whatever we may be referring to by the “process” here). Visual analytics supports memory externalisation such that the system can serve to “remind” the user of some detail when needed, rather than the user be expected to recall all previous observations of data. Similarly, users can not visualise all data at once. As system designers, we need to make decisions about the level of perception that is appropriate when data is being conveyed to the user (or at least, offer the user a means of adjusting this level). Scalability will continue to dominate visual analytics as a challenge — however, the power of the human is to identify the appropriate way of incorporating more scalable methods for data analysis — such as machine learning — to then support the investigation of the data.</p> <p>How do we account for semantics in our data? For example, think about document collections (e.g., e-mail conversations). A system can calculate metrics such as word count and word occurrences, but a computer would not understand the true definition of a word. Even if it can infer that similar words occur together, there is a need for human intervention to assess the appropriateness of the words used. We’ll explore this further in our Section on text analytics.</p> <p>Uncertainty is a fundamental challenge in data analytics. Data is gathered from a sensor (which could be a packet capturer, a video camera, a software tool or a hardware sensor). How do we know that the sensor is gathering data reliably? How can we use visual analytics to inform about our confidence in the data, or the uncertainty that may have been introduced, and how should users comprehend this information? If a sensor is 65% confident, how does the user make best use of this information? (e.g., Frenquentist vs Bayesian probabilities). There will also be uncertainty in our users — how can we ensure they will use tools in the way they are designed? How can we ensure they will act in the way that is intended (e.g., providing correct information). Could visual analytics help to identify security concerns based on how users interact with a system (either deliberately or accidentally).</p> <p>Finally, how do we evaluate a good visual analytics system? Many dashboards are developed based on intuition, or from templates, but how do we scientifically assess design choices made? There is much research in the area about how we develop guidelines for reproducable visual analytics systems, rather than working on the assumption of bespoke software development. The <a href="http://ieeevis.org/year/2021/welcome">IEEE VIS</a> community, and especially for us, the <a href="https://vizsec.org/">IEEE VizSec</a> community (Visualisation for Cyber Security), are two important research venues where this is an ongoing discussion. We show 5 examples of different visual analytics applications. When examining these, think about how design choices have been made, how they support multiple linked views for exploration, and how you may expect a user to interact with the system from start to finish. The pictures are linked where you can find the research papers, and range from topics of insider threat detection, through to online gaming, taxi trajectories, text analysis, and massive open online courses.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/394/0*L8caWExU6sU1PSU3.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/391/0*EzLZWZI1yY-78AbC.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/386/0*lJL3ErE1ItaoQTy9.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/405/0*aYjlDg2Xse47uQ8K.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/393/0*I0JVFEhFAANotP8b.png"/></figure> <h3>Further reading</h3> <ul><li><a href="https://ieeexplore.ieee.org/document/7503278">P. A. Legg, “Enhancing cyber situation awareness for Non-Expert Users using visual analytics,” 2016 International Conference On Cyber Situational Awareness, Data Analytics And Assessment (CyberSA), 2016, pp. 1–8, doi: 10.1109/CyberSA.2016.7503278.</a></li><li><a href="https://towardsdatascience.com/building-dashboards-using-dash-200-lines-of-code-ae0be08d805b">Agarwal, R. Building Dashboards using Dash. Towards Data Science (2020)</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=d914156553cc" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 05 — Visualisation</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics05visualisation/" rel="alternate" type="text/html" title="Security Data Analytics — 05 — Visualisation"/><published>2025-06-22T10:56:29+00:00</published><updated>2025-06-22T10:56:29+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics05visualisation</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics05visualisation/"><![CDATA[<h3>Security Data Analytics — Session 05 — Visualisation</h3> <p><strong><em>*** This material is session 5 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <h3>Visualisation Techniques</h3> <p>Here we will give a brief overview of different visualisation techniques, highlighting where they are effective and how they should be used.</p> <p><a href="https://bl.ocks.org/mbostock/3884955"><strong>Multi-series Line Chart</strong></a><strong>:</strong> Line charts are effective for time-series data, where the horizontal x-axis would denote time, and the y-axis would denote some numerical attribute. With colour-coding, we can depict multiple lines on the same chart, where the purpose is for comparison between two or more observed measures.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/467/0*y2AyT7vJ54jjf1_v.png"/></figure> <p><a href="https://bl.ocks.org/mbostock/3885304"><strong>Bar Chart</strong></a><strong>:</strong> This depicts numerical attributes for different discrete classes along the x-axis, rather than some continuous value. This could be some count obtained for various countries, or observations of different malware varients. Height of the bar denotes the numerical value.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/449/0*NGqaPZWgyRJQafrv.png"/></figure> <p><a href="https://bl.ocks.org/mbostock/3887118"><strong>Scatter Plot</strong></a><strong>:</strong> This is useful for comparing two different numerical attributes together, for example the number of bedrooms in a house and the associated house price. Another example may be the RAM and CPU usage of infected and benign workstations, for studying behaviour differences in a malware investigation. The scatter plot helps to identify the relationship between two indendepent variables, often referred to as the correlation between two variables. Highly correlated variables will share some statistical pattern (e.g., either that they increase or decrease together which would be a postive correlation, or that when one increases the other decreases — and visa versa — which would be a negative correlation).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/411/0*5YRG1wla3fyXObQc.png"/></figure> <p><a href="https://bl.ocks.org/mbostock/4063269"><strong>Bubble Chart</strong></a><strong>:</strong> This is actually very similar to a bar chart, in that it shows different classes or categorical attributes, and it shows a numerical value associated with this — however here rather than a bar we use a bubble. Firstly, the plot is more visually appealing than a bar chart, and so may be more suitable for engaging the desired audience. Secondly, there is no sense of order — a bar chart runs left to right, whereas bubbles are dynamic and can place wherever, be it automatically or manually. Finally, bubble charts are arguably more compact than bar charts — where a very tall bar may result in lots of white space. However, bubble charts are known to be misleading. Firstly, is the numerical quantity mapped to the diameter, the radius, or the area of each bubble? In theory, you could use any of these geometric properties of the shape, resulting in different scaling of each entry. Secondly, how easy is it to compare one bubble to the next beyond whether it is larger or smaller, for example, how easily can I identify where an attribute to twice the value of another? In such scenarios the bar chart is more suitable — comparing two lengths when side-by-side is much easier than comparing two “bubbles” — be it by diameter, radius or area — when they are arbitrarily placed on the plot. As mentioned, the bubble chart is about creating an impactful visualisation that captures the attention of the audience, rather than providing a scientific analysis tool.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/406/0*K3QwAsfDdnXDYx_k.png"/></figure> <p><a href="https://bl.ocks.org/mbostock/4062045"><strong>Force-Directed Graph</strong></a><strong>:</strong> We discussed how a scatter plot can show relationships between attributes, however this tends to be for a one-to-one mapping between two variables. How do we show one-to-many relationships? Force-directed graphs help, where points are connected by edges, and there may exist a one-to-one or one-to-many relationship between points. A prime example is a social network graph, where nodes are people and edges are whether the two people know each other (i.e., are connected). The same can apply to computers on a network. They are described as force-directed since nodes are not positioned with a fixed x and y point like on a scatter plot, but instead, nodes are positioned using a physics-based force algorithm that will treat each connection like elastic where connected points will be pulled closer together. This force layout helps to further draw out relationships between nodes, especially when a high number of nodes are depicted. However, force-directed networks should be used carefully. In a situation where many nodes are all connected together, this creates strong forces pulling together and essentially forms a cluster — often described as a ‘hairball’. If you want to show many connected nodes together, you should consider how to best filter the data so that it can remain informative.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/524/0*T9KsPNHfhuFT3VEH.png"/></figure> <p><a href="https://bl.ocks.org/jasondavies/1341281"><strong>Parallel Coordinates</strong></a><strong>:</strong> Whilst scatter plots are useful, they are limited to 2 or 3 dimensional spaces. Can we visualise information that may be higher dimensionality? Parallel coordinates achieve this, where each vertical line represents a data axis (like the x and y of a scatter plot would), however rather than denoting a point on each axis, we use a line to connect a pair of axes. We do this for each pair as the axes are displayed, so that a single data instance is essentially depicted by a line that crossed each axis. We can identify correlations between pairs of neighbouring axes — do the lines all go up or down together, or do they cross over? As in other chart types, we can colour code by class. We can also filter (or brush) axes, much like we may set a region of a scatter plot. Parallel coordinates are therefore very effective — however they may be unfamiliar to some users, and so there is a learning curve to overcome. Another limitation is that correlations can only be assessed on neighbouring axes — some implementations allows axis reordering however this can create additional overhead for the analyst.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/417/0*5US22-0-ol9eMy6t.png"/></figure> <p><a href="https://bl.ocks.org/mbostock/4063582"><strong>Treemap</strong></a><strong> and </strong><a href="https://bl.ocks.org/kerryrodden/766f8f6d31f645c39f488a0befa1e3c8"><strong>Sunburst</strong></a><strong>:</strong> Treemaps are excellent for depicting hierarchy. They were initially developed for conveying information about computer files and folder structure. Each entry is scaled based on the numerical value being considered (e.g., file size). Since a group of files may exist within the same folder, we can group them together and therefore show the collective size of the folder also (shown either by a bounding box, or by colour coding). Since the full rectangular area denotes the full space available (e.g., the entire hard drive), it can show size in relation to the full disk, and means that available space is also shown (essentially as a blank area of the chart). The sunburst is a similar concept, except it is mapped to a circle rather than a rectangular area. The hiararchical structure works outwards in the sunburst, and so is not as compact as the treemap, however, it does show proportion well just like the treemap and it does so in a striking and visually appealing way, therefore making it good for audience engagement. Some modern operating systems (e.g., Ubuntu) use the sunburst to show disk space analysis.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/367/0*OZ4BQr2lgr5y7vtI.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/319/0*265cJ3YlHrEWGne7.png"/></figure> <p><a href="http://bl.ocks.org/kevinschaul/8213691"><strong>Star Plots</strong></a><strong>:</strong> The final visualisation type we will consider here is the star plot. These essentially map multiple attributes in a small and compact format, often referred to as a glyph (where a glyph is a small depiction of multi-variate data). In this example, 8 attributes are mapped in each glyph. The mapping is similar to how a parallel coordinates plot works, except here the layout is radial rather than left-to-right.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/428/0*lwaKNroGHKLD2umq.png"/></figure> <h3>Visualisation for Cyber Security</h3> <p>Having introduced differe forms of visualisation, here we will now look at how these can be used for the purpose of cyber security. Of course, this is not an exhaustive set, but will help to illlustrate the effectiveness of visualisation techniques for analysing large complex data, which is essentially what we aim to do as part of understanding and defending large corporate networks. For more details, and further examples, I recommend looking at the two books: Applied Security Visualization by Raffael Marty and Security Data Visualisation by Greg Conti, as well as the primary text for the course.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/434/0*5pYY2j2M-1kUPbMB.png"/></figure> <p>In this example, we see parallel coordinates being used to depict network traffic across a set of 7 attributes. This image shows a comparison between regular wireless network traffic, compared against a WEP key cracking attack against the network. We can see the difference between the two activities clearly in the two images, where essentially the WEP cracking attack is scanning all available ports and uilising a single protocol. The approach is detailed further in the paper, <a href="https://ieeexplore.ieee.org/document/5718652">“Visualizing Networking Activity using Parallel Coordinates”</a> by Tricaud et al.</p> <p>In the paper <a href="https://pdfs.semanticscholar.org/66b8/1e4fe80511154703385d5d4ab2abc6164140.pdf">“Fast detection and visualization of network attacks on parallel coordinates”</a> by Choi et al., they propose the use of parallel coordinates for network traffic analysis, but use this to define small glyphs that are indicative of network behaviours. The distinguishable shape of the data plots can be treated as a signature here, to easily recognise behaivours such as worm, port scan, or DDoS.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/428/0*LdYU9MFIIzb9WTWK.png"/></figure> <p>As mentioned earlier, similar to this is the star glyph, which maps axes in a radial manner to create a connected polygon, where the length from the centre to each point denotes a variable. In the example shown here, we have 8 attributes about network packet captures mapped, and so we can show individual packets as glyphs for comparison. Glyphs are widely used in various applications, for example, insider threat detection. This example shows 18 individuals from a company and their behaviours during a 12 month period. Even with such volume data, some differences can be identified (suspicious cases are highlighted with the grey circle, two of these users are denoted in blue as potentially malicious).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/453/0*y1jye2giDBkUM2ku.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/308/0*B-3I-eo8bgcW4EeO.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/279/0*xfN0_BMK7IGVPRy7.png"/></figure> <p>We have mentioned node-link diagrams (also referred to as force-directed) for social media analysis and network profiling. Here we show three images to convey this further. In particular, we can see the complexity of the node-link diagrams as more nodes are included, and where a central node has many connections, we start to see the hairball effect mentioned earlier. This is where good visual analytics planning is required to have appropriate forms of filtering and selection to make the chart useable.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/316/0*__JKb2ll0dwKRPe0.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/252/0*PHWojTMVVH1R4BHN.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/337/0*E7-F6gJGQuuyAQd0.png"/></figure> <p>Treemaps were discussed earlier, and here we see snort alerts mapped against a tree map to show the volume of alert types, where alerts will naturally exist as part of a group (i.e., within a hierarchy).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/562/0*oBigCebTi4snX79_.png"/></figure> <p>A final example to consider is the use of visualisation for binary file analysis (we will discuss this in further detail later in the course). Greg Conti shows an excellent example of this, where binary data is mappped to pixel values to produce an image of the data. We can examine what the same image may look like using different image compression schemes (e.g., bmp, png, gif, jpeg), as well as how a Microsoft Word document may appear once password-protected or encrypted (here we see that the password-protected file does not encrypt the original data).</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/457/0*WbDB6Z-PwjU0dV0O.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/232/0*RmCeFQQYw7PQ1vRL.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/440/0*Bkkbr_7L4BhBdo-F.png"/></figure> <h3>Visual Channels</h3> <p>The final point to cover in this session is on visual channels. All visualisations are made up of visual channels, and so we need to ensure that these channels are used effectively. Some examples of channels would be colour, size, orientation, shape, texture, opacity. Spatial positioning is also a visual channel — for example how data is mapped to an axis or positioned within a space. How do we know which channels should map to which data attribute? There are no fixed rules as such — but as we discussed some of the weaknesses in visualisations earlier, we need to consider what may work best for our data. Mapping a single numerical value to a circle for example can cause confusion. We need to think about the type of data being shown. There are 4 fours we need to recognise: nominal, ordinal, interval, or ratio. Nominal data can be text labels (e.g., name) or categories (e.g., car type) — there may not be a specific order to these — we may use alphabetical ordering but that is purely for convenience. Ordinal data does have some order to it, however the difference between each possible value is unknown or not exact (for example, a threat level scale or a likert scale). Interval data is ordered and the interval between each data point is known — for example, temperature values. Ratio data is the same, however it has an absolute zero. Temperatures can be negative, however a packet size or a count of some data would be a ratio as you would not have a negative value for this.</p> <h3>Further reading</h3> <ul><li><a href="https://ieeexplore.ieee.org/abstract/document/7312772">P. A. Legg, “Visualizing the insider threat: challenges and tools for identifying malicious user activity,” 2015 IEEE Symposium on Visualization for Cyber Security (VizSec), 2015, pp. 1–7, doi: 10.1109/VIZSEC.2015.7312772.</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=492820fd7cd0" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry><entry><title type="html">Security Data Analytics — 04 — Machine Learning</title><link href="https://pa-legg.github.io/blog/2025/security-data-analytics04machine-learning/" rel="alternate" type="text/html" title="Security Data Analytics — 04 — Machine Learning"/><published>2025-06-22T10:55:49+00:00</published><updated>2025-06-22T10:55:49+00:00</updated><id>https://pa-legg.github.io/blog/2025/security-data-analytics04machine-learning</id><content type="html" xml:base="https://pa-legg.github.io/blog/2025/security-data-analytics04machine-learning/"><![CDATA[<h3>Security Data Analytics — Session 04 — Machine Learning</h3> <p><strong><em>*** This material is session 4 from the previous Security Data Analytics and Visualisation course that I led at UWE until 2024. It is now shared for reference purposes. ***</em></strong></p> <h3>What is Machine Learning?</h3> <p><a href="https://expertsystem.com/machine-learning-definition/">Machine learning</a> is a domain within artificial intelligence (AI) that provides systems with an ability to learn from experience of data observations <strong>without being explicitly programmed</strong>. What this means is that we do not need to explicitly program the rules that may help us to differentiate between categories within our data, instead we determine how the data will be presented (i.e., what are the features of the data), and we allow the machine to determine a way of organising this information. Machine learning focuses on the development of computer programs that can access data and use it learn for themselves. We can essentially think of three components: an input (the data), a function, and an output. The machine is trying to learn the function that can map inputs to some form of output, which is achieved by minimising some <strong>error measure</strong> (sometimes described as maximising a fitness function). One possible approach is to consider the difference between the expected output and the predicted output as the error measure.</p> <blockquote><em>A decision model that is not explicitly programmed, but instead is learnt through the training of example data.</em></blockquote> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*lOojO1zPvnwsdkhx.gif"/></figure> <p><strong>Supervised Learning:</strong> This is where we have a set of data observations, and we provide labels about each of these observations to inform the machine what the data essentially represents. For example, if we have a set of images that we wish to classify into groups, we can state that the output is what the image depicts (for example, is it a cat or a dog?). The input to the system is the raw image data assessed based on the colour pixel intensity values. The output of the system is a label of either ‘cat’ or ‘dog’. The function that converts pixel data to a label is what the machine attempts to learn. This is often described as <strong>classification</strong> since we are classifying the data into a series of groups. This exact same concept can be extended to many other applications, such as classifying malicious and benign software, or malware families, or even classifying types of users of a system.</p> <p><strong>Unsupervised Learning:</strong> This is where data is provided much like before however no training labels are given. Leading from our earlier example then, we may have image data of cats and dogs, however we do not have each image labelled as such. Here, the system attempts to learn a suitable way of <strong>clustering</strong> the data, under some mathematically assumptions. As an example, this could be distance-based, where it may be assumed that observations of the same type may appear close together in feature space. A scatter plot could then be used to explore the learnt separation of the data, to assess whether the groupings of the data make sense from some intuitive perspective. This can be a really powerful technique for dealing with a large volume of data fairly quickly, where labelling each data observation is not an option due to time constraints. Furthermore, some approaches may combine unsupervised learning as an initial data processing stage, to then support more efficient labelling to inform a supervised process.</p> <p>Other forms of learning also exist, such as <strong>semi-supervised</strong> (where the system may only be informed on a subset of samples, as identified through some means which could be unsupervised), <strong>active learning</strong> (which involves a human-in-the-loop to label a small subset of data based on some underlying data attributes), and <strong>reinforcement learning</strong> (which is learning based on trial-and-error, popular for learning to play video games or robotic navigation).</p> <p>Important to discuss also is the notion of training and testing. Typically, we develop a machine learning classifier based on training data. This is data that is representative of the problem domain that we are addressing, and our system may observe this data many times as part of adjusting the function that is calculated to map inputs to outputs correctly. Once we have completed sufficient iterations of this, such that the accuracy of mapping inputs to outputs on the training data is relatively high (ie., a high accuracy score is achieved), we would then test the model using a test dataset, that contains samples that were not in the training data, but are drawn form the same distribution. If we can achieve a high accuracy using the testing data also, then our model can be considered to be <strong>generalisable</strong>. Where the model performs high for training data but low for testing data, this can be described as <strong>overfitting</strong> our model to the training data. This is an important concept to grasp as the purpose of machine learning is to develop a system that can generalise to new data observations, and predict outputs on these, based on historical data patterns.</p> <h3>Search Optimisation</h3> <p>Earlier we introduced the concept of minimising some error measure, or error function. We can think about this as trying to find some minimum point on a curve — the challenge is that we do not know the minimum point ahead of time. Suppose we are at the yellow point on the curve, and we can look either one place left or right. By stepping along we can find the minimum point on the curve, however the notion of step size is important to realise. Too small a step size would mean that the time taken is too large. Too large a step size would mean that we overstep our intended solution. Furthermore, in most challenges the curve may not be a simple as a standard U-shape. Imagine a rock face, where there are ridges and nooks along the surface. We can think of these as local minima, where the point either side is greater — and so therefore have we found the mimimum point? The true mimimum is often described as the global minimum. Search optimisation aims to find the global minimum solution, in a way that can traverse this space efficiently, and can overcome local minima that may conceal the correct solution.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/1024/0*zFoEGj3mhdka5mU0.png"/></figure> <h3>Methods of Learning</h3> <p><a href="https://en.wikipedia.org/wiki/Linear_regression"><strong>Linear Regression</strong></a><strong>:</strong> Widely used in statistics, linear regression is an approach for modelling the relationship between a dependent variable and one or more explanatory, or independent, variables. This essentially gives a continuous value prediction of some outcome, based on a set of numerical inputs. For example, imagine I want to predict house prices in my local area. If I know number of bedrooms and listed price, I can develop a mathematical model to express this, where number of bedrooms is the input, and price is the output. For any number of bedrooms within my distribution, I can then predict the output price. Of course, the model may be wrong, and would likely require more attributes, such as garden size, access to schooling, whether there is a driveway, and many other factors. We see here how multiple inputs variables will inform a single output value. I could model whether a network packet is malicious or benign in a similar fashion, where multiple inputs inform a single numerical output. The important thing to note here, is that this will only model a linear relationship — i.e., there is strong linear correlation between the inputs and the output, and so this is often too simplistic for many real-world challenges, but does at least provide a useful starting point. Linear regression can be expressed in the form: y = mx + c, where m is the gradient of the line, and c is the y-intercept of the line. We can calculate the Mean Squared Error (MSE) to measure how closely the data fits the line, where the smaller this value is, the closer the fit.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/400/0*WYSEcnvFcQc69LmC.png"/></figure> <p><a href="https://en.wikipedia.org/wiki/Cluster_analysis"><strong>Clustering</strong></a><strong>:</strong> Here we want to observe when different observations form groupings of similar behaviour. We have discussed earlier the idea of clustering malware as malicious or benign. Similarly, we may have some data that is unlabelled, and we want to assign some labels to this. A popular method for this is known as k-means clustering, which will aim to identify k unique clusters within a given dataset, where data points are grouped together based on their collective mean values. Essentially, we begin with k randomised points, and for each point within our data, we determine which of our k points the data is closest to, so that we can assign a label. Once we have assigned a label to all data points, we update our k points so that each k point is the centroid of the group — which essentially is the mean in both the x and y axis, assuming we are dealing with 2 attributes in our data. We continue this process until we find a solution where the k points no longer change, and therefore our solution has stablised. We could essentially say we have minimised the error (the distance required to update the values). The practical session will delve into clustering further.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/287/0*cSGCN7-egnWdLwcV.png"/></figure> <figure><img alt="" src="https://cdn-images-1.medium.com/max/305/0*DAuV51pHi-JTehd3.png"/></figure> <p><a href="https://en.wikipedia.org/wiki/Support_vector_machine"><strong>Support Vector Machines</strong></a><strong>:</strong> Similar to how we have described our clustering approach above, SVM works through iterative search to find an optimal solution. Likewise, just as linear regresssion provides a line-of-best-fit through the data, SVM aims to fit a line that provides a decision boundary so that data points can be classified. Specifically, we measure the <a href="https://en.wikipedia.org/wiki/Euclidean_distance">euclidean distances</a>between data points nearest to the decision boundary. The objective is to maximise the distance between points and the decision bounary. The euclidean distance essentially measures the distance as a diagonal distance (think about the long side of a triangle, and how you would calculate this distance using Pythagorean Therorem). We can use the same formula as described earlier for linear regression, y = mx + c, to characterise the decision boundary line.</p> <p><a href="https://en.wikipedia.org/wiki/Dimensionality_reduction"><strong>Dimensionality Reduction</strong></a><strong>:</strong> Earlier we commented that our search optimisation may be in some higher dimensional space. We often use 2D or 3D visualisations to convey them simply because we can not easily observe dimensionlity higher than this. Yet, some dataset that has 100 different numerical attributes about each data instances could be considered to be a high dimensional dataset (100-dimensional). Is there a meaningful way that we can visualise this data to identify data instances that mayshare similarities, or at least may make it easier to summarise the key characteristics of the data instance. Dimensional reduction aims to achieve this, such that we can preserve the structure of the data in a low dimensional space that can be easier understood and visualised.</p> <p>Principal Component Analysis (PCA) is a widely used method of dimensionality reduction. For a given dataset, it essentially seeks to find the direction (or vector) of greatest variance through the data. Suppose we have some points in 2-dimensions. We can fit a line through this data, much like we have seen already. Then, we could treat this line as a new “axis” for our data, and essentially map our points against where they occur on this line. We could also imagine a similar approach if we wanted to map 3-dimensional points to 2-dimensions, by finding a plane that all points could be mapped on to (where we say plane, imagine this as a flat piece of paper being held at some orientation within our 3-dimensional points, and then placing a dot on our page where each point occurs). Other methods of dimensionality reduction include t-distributed stochastic neighbourhood embedding (t-SNE), and uniform manifold and projection (UMAP). Dimensionality reduction is useful as part of unsupervised learning, where we want to cluster data but have no training labels to inform our process.</p> <p><a href="https://en.wikipedia.org/wiki/Artificial_neural_network"><strong>Neural Networks</strong></a><strong>:</strong> Probably the most commonly described form of machine learning in use today is the neural network. The name derives from the notion of synapses in the brain firing when they receive a signal, where many signals contribute towards whether a synapse should fire or not. Here, we have an input layer (red) which takes in some attributes about our data — for example, a set of numerical features that have been derived. For classification, the output layer would relate to the possible output classes of the data, where the highest scoring node would be the predicted class. In between are a set of hidden nodes that the machine will attempt to learn a suitable numerical value for, such that input nodes map to the expected output nodes. We do this using <a href="https://en.wikipedia.org/wiki/Matrix_multiplication">matrix multiplication</a>. We will show this further in the practical session. The important detail to know is that neural networks are calculated as <em>y = sigmoid (Wx + b)</em>, where <em>x</em> is my input vector (e.g., 5 numerical values in a 5-by-1 column), <em>W</em> is a weights matrix (where the matrix has the same number of columns as the number of rows in our input vector), and <em>b</em> is a bias vector that is added as a constant. The sigmoid function then scales our resulting vector so that our values remain within our set bounds (either -1 and +1, or 0 and 1). What we have described is often considered as a feed-forward network. Since our model is likely to incorrectly predict our data initially, we need a method for updating the weight values in our hidden nodes, since these essentially dictate how our input relates to our output. This is done using a technique called <a href="https://en.wikipedia.org/wiki/Backpropagation">backpropagation</a>. This essentially works like the search optimisation technique described earlier, where we seek to minimise the distance between the predicted values and our expected values, which is achieved through the process of training the neural network.</p> <figure><img alt="" src="https://cdn-images-1.medium.com/max/469/0*hM7nVXlwo43SveAn.png"/></figure> <p>For our purpose here, we want to understand what different techniques exist for machine learning. Here we are not going to focus too much on the underlying mathematics used, although it is important to understand how these methods operate and why. Neural networks have formed the basis of much modern machine learning research. The concept of <a href="https://en.wikipedia.org/wiki/Deep_learning">Deep Learning</a> comes from having many hidden node layers in a neural network structure, such that it is a deep neural network. Furthermore, there now exist a wealth of different architectures based upon the notion of deep learning. <a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">Convolutional Neural Networks</a> have become particularly popular for image analysis tasks. This is because instead of having single vector inputs, they use square regions as input, which means they are much better at preserving spatial attributes such as the relationship between pixels in an image. The final method to mention here is <a href="https://en.wikipedia.org/wiki/Recurrent_neural_network">Recurrent Neural Networks</a>, which are designed to work on sequential forms of data. Whereas our previous learning models have treated each data instances as a discrete observation, in a recurrent model, each instance of data is dependent on what came before. A common example is language modelling — so similar to subsequence anomalies discussed in Section 3, our model could learn that the input phrase “The quick brown fox jumps over the lazy” is completed by the word “dog”.</p> <p>We have covered a lot of ground in this section, but hopefully this helps to give you a brief introduction to the diferent machine learning models that are used. In particular, we have seen how each model takes an input, performs some processing or operation, and provides an output. We have also seen how this is based on minimising or maximising some function over time through the process of training to achieve the final output. It is important to think about the task to be solved as to which method is most appropriate — are we hoping to predict a class (classification), a continuous value (regression), a group (clustering), or some complex non-linear function (neural network)?</p> <p>As a slightly aside, when using machine learning for the purpose of cyber security, it is vital that we consider the case where an adversary is able to manipulate the performance of our model. You may have seen examples of this, where image recognition systems can be made to misclassify objects, despite a well-trained model being used. Think about the impact here for up-and-coming domains such as autonomous vehicles and healthcare. This is why when we think about AI for cyber security it is fundamental that we also think about the cyber security of AI. We are merely scratching the surface here, however there is much research activity in the area of <a href="https://en.wikipedia.org/wiki/Adversarial_machine_learning">adversarial learning</a>.</p> <p>We have covered a lot in this section, and it is worth taking the time to reflect on the different techniques used in machine learning for cyber security. The practical sessions that accompany this chapter will show you how the implement clustering, linear regression, and neural networks, using Python and the Jupyter Notebook environment, to give you a feel for how the inner workings of these concepts perform. This will also help develop your understanding when using off-the-shelf libraries such as scikit-learn, to understand how the algorithms scale up and perform on larger datasets.</p> <h3>Further reading</h3> <ul><li><a href="https://www.sciencedirect.com/science/article/pii/S0167404818305546">M. Rhode, P. Burnap and K. Jones, “Early-stage malware prediction using recurrent neural networks”. Computers &amp; Security, Volume 77, August 2018, Pages 578–594.</a></li><li><a href="https://ieeexplore.ieee.org/abstract/document/8899533">A. Mills, T. Spyridopoulos and P. Legg, “Efficient and Interpretable Real-Time Malware Detection Using Random-Forest,” 2019 International Conference on Cyber Situational Awareness, Data Analytics And Assessment (Cyber SA), 2019, pp. 1–8, doi: 10.1109/CyberSA.2019.8899533.</a></li></ul> <p><img src="https://medium.com/_/stat?event=post.clientViewed&amp;referrerSource=full_rss&amp;postId=5edef0e764f0" width="1" height="1" alt=""/></p>]]></content><author><name></name></author></entry></feed>